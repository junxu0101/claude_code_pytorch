# PyTorch Machine Learning Models Created by [Claude Code](https://claude.ai/code)

The README.md file (this file) was also created by [Claude Code](https://claude.ai/code) (tweaked a little by the author of course).

## Model [1]: Food-101 Classification with PyTorch CNN
A deep learning project implementing a ResNet-based Convolutional Neural Network for classifying food images from the Food-101 dataset. This project demonstrates state-of-the-art computer vision techniques using PyTorch.

**ðŸ¤– The initial code in the notebook and the README.md file were generated by [Claude Code](https://claude.ai/code) using a simple prompt provided by the author who also checked the code, split it into multiple cells, made a few minor tweaks and tested the code.**

## Overview

This project implements a custom ResNet-inspired CNN architecture to classify images across 101 different food categories using the Food-101 dataset. The model achieves robust performance through modern deep learning techniques including batch normalization, dropout regularization, and adaptive pooling.

## Dataset

- **Dataset**: Food-101 (101 food categories)
- **Training samples**: 60,600 (80% of original training set)
- **Validation samples**: 15,150 (20% of original training set)
- **Test samples**: 25,250
- **Image size**: 224Ã—224 pixels
- **Data augmentation**: Random horizontal flip, rotation, and ImageNet normalization

## Model Architecture

The `ResNetCNN` model is a custom implementation inspired by ResNet architecture with the following key components:

### Architecture Rationale

- **Initial Conv Layer**: 7Ã—7 kernel with stride 2 for efficient feature extraction from 224Ã—224 input images
- **Batch Normalization**: Applied after each convolution for training stability and faster convergence
- **Residual-inspired Blocks**: Four progressive layers (64â†’128â†’256â†’512 channels) with 2 blocks each
- **Adaptive Global Average Pooling**: Reduces spatial dimensions to 1Ã—1 regardless of input size
- **Dropout**: 50% dropout before final classification layer to prevent overfitting
- **Final FC Layer**: Maps 512 features to 101 food categories

### Model Specifications

- **Total parameters**: 4,785,765
- **Architecture depth**: 4 main layers with progressive channel doubling
- **Activation**: ReLU throughout the network
- **Pooling**: MaxPool after initial conv, AdaptiveAvgPool before classifier

## Training Configuration

- **Optimizer**: Adam (lr=0.001, weight_decay=1e-4)
- **Loss function**: CrossEntropyLoss
- **Scheduler**: StepLR (step_size=10, gamma=0.1)
- **Batch size**: 32
- **Epochs**: 20
- **Device**: Apple Silicon MPS GPU (with CUDA/CPU fallback)

## Performance Metrics

The model training includes comprehensive tracking of:

- **Accuracy**: Classification accuracy on training/validation/test sets
- **Precision**: Weighted average precision across all classes
- **Recall**: Weighted average recall across all classes
- **Loss**: CrossEntropy loss monitoring
- **Training speed**: Real-time performance monitoring (samples/second)

### Results Summary

**Final Test Results:**
- **Test Loss**: 1.6568
- **Test Accuracy**: 56.51%
- **Test Precision**: 55.93%
- **Test Recall**: 56.51%
- **Test evaluation time**: 49.95s
- **Test inference speed**: 506.4 samples/s
- **Total project time**: 47.11 minutes

*Note: Complete training results and performance metrics are tracked during the 20-epoch training process with detailed per-epoch reporting.*

## Features

- **Multi-GPU Support**: Automatic detection of Apple Silicon MPS, NVIDIA CUDA, or CPU
- **Comprehensive Metrics**: Real-time tracking of accuracy, precision, recall, and timing
- **Model Persistence**: Automatic saving of best model based on validation loss
- **Data Visualization**: Built-in plotting for training metrics and timing analysis
- **Performance Monitoring**: Detailed timing analysis for training optimization

## File Structure

```
claude_code_pytorch/
â”œâ”€â”€ claude_code_food101_classification.ipynb  # Main training notebook
â”œâ”€â”€ README.md                                 # This file
â”œâ”€â”€ best_model.pth                           # Saved best model weights
â”œâ”€â”€ training_metrics.png                     # Training performance plots
â”œâ”€â”€ timing_analysis.png                      # Training timing analysis
â””â”€â”€ data/                                    # Food-101 dataset (auto-downloaded)
```

## Usage

1. **Environment Setup**: Ensure PyTorch, torchvision, matplotlib, scikit-learn, and numpy are installed
2. **Run Training**: Execute the Jupyter notebook `claude_code_food101_classification.ipynb`
3. **Dataset Download**: Food-101 dataset will be automatically downloaded on first run
4. **Model Training**: 20-epoch training with automatic best model saving
5. **Results**: View training metrics plots and final test evaluation

**The code has been tested on both MacBook Pro /w Apple M4 and Ubuntu 24.04 /w Nvidia GPU**

## Technical Highlights

- **Efficient Data Loading**: Multi-worker DataLoader with optimized batch processing
- **Memory Optimization**: Gradient accumulation and efficient tensor operations
- **Real-time Monitoring**: Batch-level progress tracking with ETA estimation
- **Robust Validation**: Separate validation pipeline with comprehensive metrics
- **Reproducible Results**: Systematic experiment tracking and model persistence

## Requirements

- Python 3.7+ (the Python version used by the author to test the code was **3.11.13**)
- PyTorch 1.9+ (the PyTorch version used by the author to test the code was **2.7.1**)
- torchvision
- matplotlib
- scikit-learn
- numpy

---

*This implementation demonstrates modern deep learning best practices for image classification tasks, combining architectural innovations with robust training methodology.*