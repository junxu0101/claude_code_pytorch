# PyTorch Machine Learning Models Created by [Claude Code](https://claude.ai/code)

The README.md file (this file) was also created by [Claude Code](https://claude.ai/code) (tweaked a little by the author of course).

## Model [1]: Food-101 Classification with PyTorch CNN
A deep learning project implementing a ResNet-based Convolutional Neural Network for classifying food images from the Food-101 dataset. This project demonstrates state-of-the-art computer vision techniques using PyTorch.

**ðŸ¤– The initial code in the notebook and the README.md file were generated by [Claude Code](https://claude.ai/code) using a simple prompt provided by the author who also checked the code, split it into multiple cells, made a few minor tweaks and tested the code.**

## Overview

This project implements a custom ResNet-inspired CNN architecture to classify images across 101 different food categories using the Food-101 dataset. The model achieves robust performance through modern deep learning techniques including batch normalization, dropout regularization, and adaptive pooling.

## Dataset

- **Dataset**: Food-101 (101 food categories)
- **Training samples**: 60,600 (80% of original training set)
- **Validation samples**: 15,150 (20% of original training set)
- **Test samples**: 25,250
- **Image size**: 224Ã—224 pixels
- **Data augmentation**: Random horizontal flip, rotation, and ImageNet normalization

## Model Architecture

The `ResNetCNN` model is a custom implementation inspired by ResNet architecture with the following key components:

### Architecture Rationale

- **Initial Conv Layer**: 7Ã—7 kernel with stride 2 for efficient feature extraction from 224Ã—224 input images
- **Batch Normalization**: Applied after each convolution for training stability and faster convergence
- **Residual-inspired Blocks**: Four progressive layers (64â†’128â†’256â†’512 channels) with 2 blocks each
- **Adaptive Global Average Pooling**: Reduces spatial dimensions to 1Ã—1 regardless of input size
- **Dropout**: 50% dropout before final classification layer to prevent overfitting
- **Final FC Layer**: Maps 512 features to 101 food categories

### Model Specifications

- **Total parameters**: 4,785,765
- **Architecture depth**: 4 main layers with progressive channel doubling
- **Activation**: ReLU throughout the network
- **Pooling**: MaxPool after initial conv, AdaptiveAvgPool before classifier

## Training Configuration

- **Optimizer**: Adam (lr=0.001, weight_decay=1e-4)
- **Loss function**: CrossEntropyLoss
- **Scheduler**: StepLR (step_size=10, gamma=0.1)
- **Batch size**: 32
- **Epochs**: 20
- **Device**: Apple Silicon MPS GPU (with CUDA/CPU fallback)

## Performance Metrics

The model training includes comprehensive tracking of:

- **Accuracy**: Classification accuracy on training/validation/test sets
- **Precision**: Weighted average precision across all classes
- **Recall**: Weighted average recall across all classes
- **Loss**: CrossEntropy loss monitoring
- **Training speed**: Real-time performance monitoring (samples/second)

### Results Summary

**Final Test Results:**
- **Test Loss**: 1.6568
- **Test Accuracy**: 56.51%
- **Test Precision**: 55.93%
- **Test Recall**: 56.51%
- **Test evaluation time**: 49.95s
- **Test inference speed**: 506.4 samples/s
- **Total training time**: 47.11 minutes

*Note: Complete training results and performance metrics are tracked during the 20-epoch training process with detailed per-epoch reporting.*

## Features

- **Multi-GPU Support**: Automatic detection of Apple Silicon MPS, NVIDIA CUDA, or CPU
- **Comprehensive Metrics**: Real-time tracking of accuracy, precision, recall, and timing
- **Model Persistence**: Automatic saving of best model based on validation loss
- **Data Visualization**: Built-in plotting for training metrics and timing analysis
- **Performance Monitoring**: Detailed timing analysis for training optimization

## File Structure

```
claude_code_pytorch/
â”œâ”€â”€ claude_code_food101_classification.ipynb  # Main training notebook
â”œâ”€â”€ README.md                                 # This file
â”œâ”€â”€ best_model.pth                           # Saved best model weights
â”œâ”€â”€ training_metrics.png                     # Training performance plots
â”œâ”€â”€ timing_analysis.png                      # Training timing analysis
â””â”€â”€ data/                                    # Food-101 dataset (auto-downloaded)
```

## Usage

1. **Environment Setup**: Ensure PyTorch, torchvision, matplotlib, scikit-learn, and numpy are installed
2. **Run Training**: Execute the Jupyter notebook `claude_code_food101_classification.ipynb`
3. **Dataset Download**: Food-101 dataset will be automatically downloaded on first run
4. **Model Training**: 20-epoch training with automatic best model saving
5. **Results**: View training metrics plots and final test evaluation

**The code has been tested on both MacBook Pro /w Apple M4 and Ubuntu 24.04 /w Nvidia GPU**

## Technical Highlights

- **Efficient Data Loading**: Multi-worker DataLoader with optimized batch processing
- **Memory Optimization**: Gradient accumulation and efficient tensor operations
- **Real-time Monitoring**: Batch-level progress tracking with ETA estimation
- **Robust Validation**: Separate validation pipeline with comprehensive metrics
- **Reproducible Results**: Systematic experiment tracking and model persistence

## Requirements

- Python 3.7+ (the Python version used by the author to test the code was **3.11.13**)
- PyTorch 1.9+ (the PyTorch version used by the author to test the code was **2.7.1**)
- torchvision
- matplotlib
- scikit-learn
- numpy

---

*This implementation demonstrates modern deep learning best practices for image classification tasks, combining architectural innovations with robust training methodology.*

## Model [2]: BERT Text Classifier for IMDb Movie Reviews

A comprehensive implementation of a BERT-based text classifier for sentiment analysis using PyTorch and the Transformers library. This project demonstrates state-of-the-art natural language processing techniques for binary sentiment classification.

**ðŸ¤– The initial code in the notebook was generated by [Claude Code](https://claude.ai/code) using a simple prompt provided by the author who also checked the code, made minor tweaks and tested the code**

## Overview

The bert_imdb_classifier.ipynb notebook implements a fine-tuned BERT model for sentiment analysis on movie reviews from the IMDb dataset. The model achieves excellent performance through transfer learning, leveraging the pre-trained `bert-base-uncased` model with a custom classification head.

## Dataset

- **Dataset**: IMDb Movie Reviews (50,000 total samples)
- **Training samples**: 35,000 (70% of dataset)
- **Validation samples**: 7,500 (15% of dataset)  
- **Test samples**: 7,500 (15% of dataset)
- **Classes**: Binary (Positive/Negative sentiment)
- **Text preprocessing**: BERT tokenization with 512 max sequence length

## Model Architecture

The `BERTTextClassifier` model combines pre-trained BERT with a custom classification head:

### Architecture Components

- **Base Model**: Pre-trained BERT (`bert-base-uncased`) for contextual embeddings
- **Pooling**: Uses [CLS] token representation from BERT's pooler output
- **Dropout**: 30% dropout for regularization
- **Classification Head**: Linear layer mapping 768 BERT features to 2 classes

### Model Specifications

- **Total parameters**: 109,483,778
- **Trainable parameters**: All parameters fine-tuned
- **Input length**: 512 tokens maximum
- **Tokenizer**: BERT WordPiece tokenization

## Training Configuration

- **Optimizer**: AdamW (lr=2e-5, weight_decay=default)
- **Loss function**: CrossEntropyLoss
- **Scheduler**: Linear warmup with decay
- **Batch size**: 16
- **Epochs**: 4
- **Device**: NVIDIA CUDA GPU (with CPU fallback)

## Performance Metrics

The model training includes comprehensive tracking of:

- **Accuracy**: Classification accuracy on training/validation/test sets
- **Precision**: Weighted average precision across both classes
- **Recall**: Weighted average recall across both classes
- **F1-Score**: Weighted F1-score for balanced evaluation
- **Loss**: CrossEntropy loss monitoring with gradient clipping

### Results Summary

**Final Test Results:**
- **Test Loss**: 0.2101
- **Test Accuracy**: 93.95%
- **Test Precision**: 93.95%
- **Test Recall**: 93.95%
- **Test F1-Score**: 93.95%
- **Best Validation Accuracy**: 94.79%
- **Total training time**: 139.53 minutes (~2.3 hours)

*Note: Complete training results with per-epoch metrics are included in the notebook with full outputs.*

## Features

- **Pre-trained BERT**: Leverages powerful language understanding from BERT-base
- **Comprehensive Metrics**: Real-time tracking of accuracy, precision, recall, and F1-score
- **Model Persistence**: Automatic saving of best model based on validation accuracy
- **Training Visualization**: Built-in plotting for loss, accuracy, learning rate, and timing
- **Example Predictions**: Interactive sentiment prediction with confidence scores
- **Confusion Matrix**: Detailed performance analysis visualization

## File Structure

```
claude_code_pytorch/
â”œâ”€â”€ bert_imdb_classifier.ipynb           # Main training notebook
â”œâ”€â”€ README.md                            # This file
â”œâ”€â”€ best_bert_model.pth                  # Saved BERT model weights
â”œâ”€â”€ bert_training_metrics.png            # BERT training performance plots
â”œâ”€â”€ bert_confusion_matrix.png            # BERT model performance heatmap
â””â”€â”€ imdb_data.csv                        # Cached IMDb dataset
```

## Usage

1. **Environment Setup**: Ensure required packages are installed (see Requirements)
2. **Run Training**: Execute the Jupyter notebook `bert_imdb_classifier.ipynb`
3. **Dataset Download**: IMDb dataset will be automatically downloaded on first run
4. **Model Training**: 4-epoch fine-tuning with automatic best model saving
5. **Results**: View training metrics plots and final test evaluation

**The code has been tested and includes complete cell outputs demonstrating successful execution.**

## Technical Highlights

- **Transfer Learning**: Fine-tuning pre-trained BERT for domain-specific sentiment analysis
- **Efficient Tokenization**: BERT WordPiece tokenization with attention masks
- **Gradient Clipping**: Prevents exploding gradients during fine-tuning
- **Learning Rate Scheduling**: Linear warmup and decay for optimal convergence
- **Robust Evaluation**: Separate validation pipeline with detailed classification metrics

## Requirements

- Python 3.7+ (the Python version used for the full run was **3.11.13**)
- torch - PyTorch deep learning framework (the PyTorch version used for the full run was **2.7.1**)
- torchvision - Computer vision utilities for PyTorch  
- transformers - Hugging Face transformers library for BERT
- datasets - Hugging Face datasets library for IMDb data loading
- scikit-learn - Machine learning metrics and evaluation tools
- matplotlib - Plotting and visualization
- seaborn - Statistical data visualization
- pandas - Data manipulation and analysis
- numpy - Numerical computing

---

*This implementation demonstrates modern NLP best practices for text classification tasks, combining pre-trained language models with robust fine-tuning methodology.*

## Model [3]: Deep Factorization Machine for CTR Prediction on Criteo Dataset

A comprehensive implementation of a Deep Factorization Machine (Deep FM) model for click-through rate prediction using PyTorch. This project demonstrates advanced deep learning techniques for recommendation systems and computational advertising.

**ðŸ¤– The initial code in the notebook was generated by [Claude Code](https://claude.ai/code) using a prompt provided by the author who also checked the code, went a few iterations with Claude Code to improve the implementation, and tested the code thoroughly**

## Overview

The deep_fm_criteo_ctr.ipynb notebook implements a Deep FM model from scratch for CTR prediction on the Criteo dataset. The model combines linear, factorization machine, and deep neural network components to capture feature interactions at different levels, with comprehensive anti-overfitting measures.

## Dataset

- **Dataset**: Criteo CTR Prediction Dataset (1,000,000 samples subset)
- **Training samples**: 64,000 (64% of dataset)
- **Validation samples**: 16,000 (16% of dataset)
- **Test samples**: 20,000 (20% of dataset)
- **Classes**: Binary (Click/No Click)
- **Features**: 13 numerical + 26 categorical features
- **CTR Rate**: ~22.7% (realistic for display advertising)

## Model Architecture

The `DeepFMModel` combines three complementary components for comprehensive feature interaction modeling:

### Architecture Components

- **Linear Component**: First-order feature interactions with individual weights
- **FM Component**: Second-order feature interactions using factorization with embeddings
- **Deep Component**: Higher-order interactions through multi-layer neural networks
- **Anti-Overfitting**: Extensive regularization including dropout, L2 penalty, and progressive regularization

### Model Specifications

- **Embedding dimension**: 8 (reduced for regularization, and may be 16 for certain configurations)
- **Hidden layers**: [256, 128] with batch normalization
- **Dropout rates**: Progressive (0.5 â†’ 0.55 â†’ 0.6 across layers)
- **Feature handling**: Both numerical and categorical features in all components
- **Regularization**: L2 penalty, weight decay, gradient clipping, early stopping

## Training Configuration

- **Optimizer**: Adam (lr=0.0005, weight_decay=1e-4)
- **Loss function**: BCELoss with L2 regularization penalty
- **Scheduler**: ReduceLROnPlateau (factor=0.3, patience=2)
- **Batch size**: 1024
- **Epochs**: 20 (with early stopping), was increased to 50 later
- **Device**: Apple Silicon MPS GPU (with CUDA/CPU fallback)

## Performance Metrics

The model training includes comprehensive tracking of:

- **AUC-ROC**: Primary metric for CTR prediction evaluation
- **AUC-PR**: Precision-Recall AUC for imbalanced dataset assessment
- **Accuracy**: Binary classification accuracy with 0.5 threshold
- **Loss Components**: BCE loss + L2 regularization penalty tracking
- **Component Analysis**: Learnable weights showing contribution of linear/FM/deep parts

### Anti-Overfitting Features

**Enhanced Regularization:**
- **Embedding regularization**: Smaller initialization (std=0.01) and dropout
- **Progressive dropout**: Increasing rates in deeper layers
- **L2 penalty**: Custom regularization for non-embedding parameters
- **Gradient clipping**: max_norm=0.5 for training stability

**Advanced Training Control:**
- **Multi-criteria early stopping**: Monitors both AUC and loss divergence
- **Learning rate decay**: Aggressive reduction when validation plateaus
- **Component weight balancing**: Learnable combination of model parts

## Features

- **Custom Deep FM Implementation**: Built from scratch without external FM libraries
- **Comprehensive Regularization**: Multiple anti-overfitting strategies
- **Flexible Architecture**: Configurable components (can disable FM or deep parts)
- **Advanced Preprocessing**: Handles missing values and categorical encoding
- **Rich Visualization**: ROC/PR curves, training metrics, calibration plots
- **Component Analysis**: Shows contribution of linear, FM, and deep parts

## File Structure

```
claude_code_pytorch/
â”œâ”€â”€ deep_fm_criteo_ctr.ipynb           # Main Deep FM training notebook
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ best_deep_fm_model.pth             # Saved Deep FM model weights
â”œâ”€â”€ deep_fm_training_metrics.png       # Deep FM training visualization
â”œâ”€â”€ deep_fm_roc_pr_curves.png          # Deep FM ROC and PR curves
â”œâ”€â”€ deep_fm_additional_analysis.png    # Deep FM analysis plots
â””â”€â”€ criteo_data.csv                    # Cached Criteo dataset
```

## Usage

1. **Environment Setup**: Ensure required packages are installed (see Requirements)
2. **Run Training**: Execute the Jupyter notebook `deep_fm_criteo_ctr.ipynb`
3. **Dataset Loading**: Criteo dataset will be loaded from local file and cached
4. **Model Training**: Up to 50 epochs with comprehensive early stopping
5. **Results**: View training metrics, ROC/PR curves, and component analysis

- Note: please download Kaggle's criteo-small data set from this location https://www.kaggle.com/datasets/leonerd/criteo-small, unzip the file, and put the file in the same directory as the notebook and name the file criteo_train_1m.txt.

**The code includes extensive regularization measures to prevent overfitting commonly seen in CTR prediction models.**

## Technical Highlights

- **Proper FM Implementation**: Handles interactions between ALL features (num-num, cat-cat, num-cat)
- **Advanced Regularization**: Multi-level dropout, L2 penalty, progressive regularization
- **Component Balancing**: Learnable weights to optimize linear/FM/deep contributions
- **Overfitting Prevention**: Comprehensive measures based on CTR prediction best practices
- **Flexible Experimentation**: Easy to disable components for ablation studies

## Test Results

- The model with all 3 components activated - linear, FM and deep layers, is too complex for the dataset and the training had to be heavily regularized to overcome overfitting, which caused the model to learn very slowly and the result wasn't optimal. The best result achieved was Test Loss: 0.4785 and Test AUC-ROC: 0.7807, and the learned contributions of the 3 components are: Linear: 0.324, FM: 0.382 and Deep: 0.294. If you are interested in the configuration, please check one of the versions of the deep_fm_criteo_ctr notebook in the commit history.
- The model with linear and deep later components activated without FM, performed very well. The best result achieved was Test Loss: 0.4619 and Test AUC-ROC: 0.7862, and the learned contributions of the 3 components are: Linear: 0.814, FM: 0.048 and Deep: 0.138. It looks like the contribution from the deep layers is small. If you are interested in the configuration, please check one of the versions of the deep_fm_criteo_ctr notebook in the commit history.
- The model with linear and FM components activated without deep layers, also performed very well. The best result achieved was Test Loss: 0.4792 and Test AUC-ROC: 0.7862, and the learned contributions of the 3 components are: Linear: 0.547, FM: 0.349 and Deep: 0.103. The contribution from FM was significant although the major contribution was still from linear. If you are interested in the configuration, please check one of the versions of the deep_fm_criteo_ctr notebook in the commit history.

The search in the hyperparameter space was not exhaustive during testing, so the "best" results listed above may not be the actual best results.

## Requirements

- Python 3.7+ (the Python version used for development was **3.11.13**)
- torch - PyTorch deep learning framework (the PyTorch version used was **2.7.1**)
- torchvision - Computer vision utilities for PyTorch
- scikit-learn - Machine learning metrics and evaluation tools
- matplotlib - Plotting and visualization
- seaborn - Statistical data visualization
- pandas - Data manipulation and analysis
- numpy - Numerical computing
- tqdm - Progress bars for training loops

---

*This implementation demonstrates modern deep learning best practices for CTR prediction tasks, combining factorization machines with deep neural networks and comprehensive regularization strategies.*